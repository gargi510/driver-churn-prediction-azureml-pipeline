# -*- coding: utf-8 -*-
"""Ola Churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z2PP8IRSnVhpXBPbHvjwBFQwSX4-Juln
"""

!pip install catboost

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.impute import KNNImputer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, roc_auc_score, roc_curve
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier

df = pd.read_csv('ola_driver.csv')

# Descriptive statistics
print("\nDescriptive statistics (numeric columns):")
df.describe()
df.info()

# Missing values
print("\nMissing values in each column:")
print(df.columns[df.isnull().any()].tolist())

# Number of unique values per column
print("\nNumber of unique values per column:")
df.nunique()

"""Date column is of object type. needs to be conerted
gender, age, last working day have missing val. need to be imputed
"""

df['Reporting_Date'] = pd.to_datetime(
    df['MMM-YY'].apply(lambda x: '/'.join(x.split('/')[1:]) if isinstance(x, str) else None),
    format='%m/%y',
    errors='coerce'
)
df['Dateofjoining'] = pd.to_datetime(df['Dateofjoining'], dayfirst=True, errors='coerce')
df['LastWorkingDate'] = pd.to_datetime(df['LastWorkingDate'], dayfirst=True, errors='coerce')

#KNN Imputation on numeric columns
num_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()
imputer = KNNImputer(n_neighbors=5)
df[num_cols] = imputer.fit_transform(df[num_cols])

# KNN Impute 'Age' and 'Gender'
df[['Age', 'Gender']] = KNNImputer(n_neighbors=5).fit_transform(df[['Age', 'Gender']])
df['Age'] = df['Age'].round().astype(int)
df['Gender'] = df['Gender'].round().astype(int)

"""Feature engineering and bringing data to driver level"""

#Aggregate per Driver_ID
agg_df = df.groupby('Driver_ID').agg({
    'Age': 'mean',
    'Gender': lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0],
    'City': lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0],
    'Education_Level': lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0],
    'Income': 'mean',
    'Dateofjoining': 'min',
    'Joining Designation': lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0],
    'Grade': 'median',
    'Total Business Value': 'mean',
    'Quarterly Rating': 'median',
    'Reporting_Date': 'max',
    'LastWorkingDate': 'max'
}).reset_index()

# QuarterlyRating_Increased
df_sorted = df.sort_values('Reporting_Date')
rating_inc = df_sorted.groupby('Driver_ID')['Quarterly Rating'] \
                      .apply(lambda x: int((x.diff() > 0).any())) \
                      .reset_index(name='QuarterlyRating_Increased')

# Income_Increased
income_inc = df_sorted.groupby('Driver_ID')['Income'] \
                      .apply(lambda x: int((x.diff() > 0).any())) \
                      .reset_index(name='Income_Increased')

# Target Variable - Attrition
attrition = df.groupby('Driver_ID')['LastWorkingDate'] \
              .apply(lambda x: int(x.notnull().any())) \
              .reset_index(name='Attrition')

final_df = agg_df.merge(rating_inc, on='Driver_ID') \
                 .merge(income_inc, on='Driver_ID') \
                 .merge(attrition, on='Driver_ID')
final_df.head()

final_df['Age'] = final_df['Age'].round(0).astype(int)
final_df['Grade'] = final_df['Grade'].round(0).astype(int)
final_df['Quarterly Rating'] = final_df['Quarterly Rating'].round(0).astype(int)

print(final_df.head(5))
print(final_df.describe())
print(final_df.info())

import pandas as pd
from scipy.stats import chi2_contingency

# Columns to test as categorical
cat_vars = ['Age', 'Gender', 'City', 'Education_Level', 'Joining Designation', 'Grade', 'Quarterly Rating']
target = 'Attrition'

for col in cat_vars:
    # Create a contingency table
    contingency_table = pd.crosstab(final_df[col], final_df[target])

    # Perform Chi-Square test
    chi2, p, dof, expected = chi2_contingency(contingency_table)

    print(f"Variable: {col}")
    print(f"Chi-Square Statistic: {chi2:.4f}")
    print(f"P-Value: {p:.4e}")
    print(f"Degrees of Freedom: {dof}")

    if p < 0.05:
        print(f"=> {col} is statistically significant for Attrition (reject H0).")
    else:
        print(f"=> {col} is NOT statistically significant for Attrition (fail to reject H0).")
    print("-" * 50)

"""Univariatr Analysis"""

import matplotlib.pyplot as plt

# Calculate proportion of each Attrition class
prop = final_df['Attrition'].value_counts(normalize=True).sort_index()  # index 0 and 1

colors = ['green', 'red']

fig, ax = plt.subplots(figsize=(6, 2))

# Create horizontal bar with two segments
ax.barh(0, prop[0], color=colors[0], edgecolor='black')
ax.barh(0, prop[1], left=prop[0], color=colors[1], edgecolor='black')

# Add text labels centered on each segment
ax.text(prop[0]/2, 0, f'{prop[0]*100:.1f}%', va='center', ha='center', color='white', fontweight='bold', fontsize=14)
ax.text(prop[0] + prop[1]/2, 0, f'{prop[1]*100:.1f}%', va='center', ha='center', color='white', fontweight='bold', fontsize=14)

# Remove y-axis ticks and labels
ax.set_yticks([])
# Remove x-axis ticks and labels
ax.set_xticks([])
# Remove frame
for spine in ax.spines.values():
    spine.set_visible(False)

plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Filter churned employees
churned_df = final_df[final_df['Attrition'] == 1].copy()

# Step 2: Map values
education_mapping = {0: '10+', 1: '12+', 2: 'Graduate'}
gender_mapping = {0: 'Male', 1: 'Female'}

churned_df['Education_Level'] = churned_df['Education_Level'].map(education_mapping)
churned_df['Gender'] = churned_df['Gender'].map(gender_mapping)

# Step 3: Check for nulls and convert to string (for safety)
cat_cols = ['Gender', 'City', 'Education_Level', 'Grade','Joining Designation', 'Quarterly Rating']
churned_df[cat_cols] = churned_df[cat_cols].astype(str).fillna('Unknown')

# Step 4: Set up plot
fig, axes = plt.subplots(2, 3, figsize=(14, 10))
axes = axes.flatten()

for i, col in enumerate(cat_cols):
    # Get count and sort order
    value_counts = churned_df[col].value_counts()
    order = value_counts.index.tolist()
    counts = value_counts.values

    # Generate red gradient palette (darkest = highest count)
    colors = sns.color_palette("Reds", len(order))[::-1]
    palette = dict(zip(order, colors))

    sns.countplot(data=churned_df, x=col, order=order, palette=palette, ax=axes[i])
    axes[i].set_title(f'Churn Count by {col}')
    axes[i].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid")

# Map values to Yes/No labels
plot_df = final_df.copy()
for col in ['QuarterlyRating_Increased', 'Income_Increased', 'Attrition']:
    plot_df[col] = plot_df[col].map({0: 'No', 1: 'Yes'})

palette = {'No': 'green', 'Yes': 'red'}

fig, axes = plt.subplots(1, 2, figsize=(14, 6))

def plot_prop(ax, feature):
    prop_df = (plot_df.groupby([feature, 'Attrition']).size()
                       .unstack(fill_value=0)
                       .apply(lambda x: x / x.sum(), axis=1))
    prop_df.plot(kind='barh', stacked=True, color=[palette[col] for col in prop_df.columns], ax=ax)
    ax.set(xlabel='Proportion', ylabel=feature, title=f'Proportion of Attrition by {feature}')
    ax.legend(title='Attrition', loc='lower right')

    for i, row in enumerate(prop_df.itertuples(index=False)):
        cum = 0
        for val, col in zip(row, prop_df.columns):
            if val > 0.02:
                ax.text(cum + val/2, i, f'{val*100:.1f}%', ha='center', va='center', color='white', fontsize=10, fontweight='bold')
            cum += val

plot_prop(axes[0], 'QuarterlyRating_Increased')
plot_prop(axes[1], 'Income_Increased')

plt.tight_layout()
plt.show()

num_cols = ['Age', 'Income', 'Total Business Value']
colors = ['green', 'red']  # index 0 → green (Attrition=0), index 1 → red (Attrition=1)

# Histogram (neutral color)
for col in num_cols:
    plt.figure()
    sns.histplot(final_df[col], kde=True, bins=30, color='skyblue')
    plt.title(f'Distribution of {col}')
    plt.show()

# Boxplots colored by Attrition using the defined colors
for col in num_cols:
    plt.figure()
    sns.boxplot(x='Attrition', y=col, data=final_df, palette=colors)
    plt.title(f'{col} by Attrition')
    plt.show()

"""Bivariate"""

custom_palette = {0: "#2ca02c", 1: "#d62728"}  # green and red hex codes

sns.pairplot(final_df[num_cols + ['Attrition']],hue='Attrition',diag_kind='kde',corner=True, palette=custom_palette)

plt.show()

plt.figure(figsize=(12, 10))
corr = final_df[num_cols + ['Attrition']].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Matrix Including Derived Features')
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

final_df.info()

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import numpy as np

# 1. Calculate tenure
final_df['Tenure'] = (final_df['Reporting_Date'] - final_df['Dateofjoining']).dt.days

# 2. Drop datetime and ID columns
final_df = final_df.drop(columns=['Dateofjoining', 'Reporting_Date', 'LastWorkingDate', 'Driver_ID'], errors='ignore')

# 3. Drop 'Gender' and 'Income_Increased' as per your note
final_df = final_df.drop(columns=['Gender', 'Income_Increased'], errors='ignore')

# 4. Separate features and target
X = final_df.drop(columns=['Attrition'], errors='ignore')
y = final_df['Attrition'].astype(int)

# 5. Label encode 'City' if exists
if 'City' in X.columns:
    X['City'] = LabelEncoder().fit_transform(X['City'].astype(str))

# 6. Convert bool columns to int
bool_cols = X.select_dtypes(include='bool').columns
X[bool_cols] = X[bool_cols].astype(int)

# 7. Create interaction features based on feature importance
X['Income_per_Tenure'] = X['Income'] / (X['Tenure'] + 1)
X['Grade_Income_Interaction'] = X['Grade'] * X['Income']
X['BusinessValue_per_Grade'] = X['Total Business Value'] / (X['Grade'] + 1)

# 8. Handle any inf/-inf and missing values
X = X.replace([np.inf, -np.inf], np.nan)
X = X.fillna(0)

X = X.drop(columns=['Quarterly Rating', 'Grade'], errors='ignore')

# 9. Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

X_train_sm, y_train_sm = SMOTE(random_state=42).fit_resample(X_train, y_train)

num_cols = X_train_sm.select_dtypes(include=[np.number]).columns.tolist()
# Initialize scaler and fit on training
scaler = StandardScaler()
X_train_sm[num_cols] = scaler.fit_transform(X_train_sm[num_cols])
X_test[num_cols] = scaler.transform(X_test[num_cols])

from lightgbm import LGBMClassifier
from sklearn.model_selection import RandomizedSearchCV
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from scipy.stats import randint, uniform

# Define model
lgbm = LGBMClassifier(random_state=42)

# Expanded parameter distribution for random search
param_dist = {
    'n_estimators': randint(100, 300),
    'num_leaves': randint(20, 60),
    'learning_rate': uniform(0.01, 0.2),
    'max_depth': randint(3, 10),
    'min_child_samples': randint(5, 30),
    'subsample': uniform(0.6, 0.4),
    'colsample_bytree': uniform(0.6, 0.4),
    'reg_alpha': uniform(0, 1),
    'reg_lambda': uniform(0, 1)
}

# Randomized search with 50 iterations, 3-fold CV, ROC AUC scoring
random_search = RandomizedSearchCV(
    lgbm,
    param_distributions=param_dist,
    n_iter=50,
    scoring='roc_auc',
    cv=3,
    n_jobs=-1,
    random_state=42,
    verbose=1
)

# Fit on training data
random_search.fit(X_train_sm, y_train_sm)

print(f"Best params: {random_search.best_params_}")

# Best estimator
best_lgbm = random_search.best_estimator_

# Feature importance
importances = best_lgbm.feature_importances_
feature_names = X_train_sm.columns

fi_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values(by='Importance', ascending=False)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(fi_df['Feature'], fi_df['Importance'])
plt.gca().invert_yaxis()
plt.title('LightGBM Feature Importance')
plt.xlabel('Importance')
plt.show()

print(best_lgbm.feature_importances_)

print(fi_df)

from sklearn.metrics import classification_report

# Predict on test set
y_pred = best_lgbm.predict(X_test)

# Print classification report
print(classification_report(y_test, y_pred))

'''models = {
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "LightGBM": LGBMClassifier(random_state=42),
    "RandomForest": RandomForestClassifier(random_state=42),
    "ExtraTrees": ExtraTreesClassifier(random_state=42),
    "CatBoost": CatBoostClassifier(random_seed=42, verbose=0),
    "AdaBoost": AdaBoostClassifier(random_state=42),
    "GradientBoosting": GradientBoostingClassifier(random_state=42),
}
param_grids = {
    "XGBoost": {
        'n_estimators': [100, 150],
        'max_depth': [4, 6],
        'learning_rate': [0.05, 0.1]
    },
    "LightGBM": {
        'n_estimators': [100, 150],
        'num_leaves': [31, 40],
        'learning_rate': [0.05, 0.1]
    },
    "RandomForest": {
        'n_estimators': [100, 150],
        'max_depth': [None, 10],
        'min_samples_split': [2, 5]
    },
    "ExtraTrees": {
        'n_estimators': [100, 150],
        'max_depth': [None, 10],
        'min_samples_split': [2, 5]
    },
    "CatBoost": {
        'iterations': [100, 150],
        'depth': [4, 6],
        'learning_rate': [0.05, 0.1]
    },
    "AdaBoost": {
        'n_estimators': [50, 100],
        'learning_rate': [0.05, 0.1, 0.2]
    },
    "GradientBoosting": {
        'n_estimators': [100, 150],
        'max_depth': [3, 5],
        'learning_rate': [0.05, 0.1]
    }
}

best_estimators = {}

for name, model in models.items():
    print(f"Training and tuning {name}...")
    grid = GridSearchCV(model, param_grids[name], cv=3, scoring='roc_auc', n_jobs=-1)
    grid.fit(X_train_sm, y_train_sm)
    best_estimators[name] = grid.best_estimator_
    print(f"Best params for {name}: {grid.best_params_}\n")

# Evaluate models
plt.figure(figsize=(10, 7))

for name, estimator in best_estimators.items():
    y_pred = estimator.predict(X_test)
    y_proba = estimator.predict_proba(X_test)[:, 1]

    print(f"--- {name} Classification Report ---")
    print(classification_report(y_test, y_pred))

    roc_auc = roc_auc_score(y_test, y_proba)
    print(f"{name} ROC AUC: {roc_auc:.4f}\n")

    fpr, tpr, _ = roc_curve(y_test, y_proba)
    plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc:.3f})")

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison of Ensemble Models')
plt.legend()
plt.show()'''
